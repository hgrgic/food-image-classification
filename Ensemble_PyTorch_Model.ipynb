{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "This notebook is representing the pipeline that was used to achive generation of multiple models whose output were ensembled at later stage. Models were based on ResNet 50. First we trained FC layer for 1 eph, and then we trained ResNet50-Layer4 for 5 eph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch\n",
    "from torch.optim.optimizer import Optimizer, required\n",
    "\n",
    "import time\n",
    "import zipfile\n",
    "import datetime\n",
    "from shutil import copyfile\n",
    "from torchsummary import summary\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Copying\n",
    "Since we were running everything on Google Collab, this part would ensure that the data got copied from the mounted Google Drive to the Collab file system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "groot = '/content/drive/My Drive/AML'\n",
    "data_zip = 'custom_split_gauss.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data copy procedure\n",
    "\n",
    "os.mkdir(\"data\")\n",
    "copyfile(groot+\"/\"+data_zip, \"custom_split_gauss.zip\")\n",
    "with zipfile.ZipFile(data_zip,\"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loding and Transformations\n",
    "This part was used for loding of the data into the pytorch data structres, as well as for defining PCA Lighting data augmentation obtained from the referenced GitHub repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Transforms to the Data\n",
    "image_transforms = { \n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomCrop(size=224, pad_if_needed = True, padding_mode='reflect'),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#General PyTorch code structre achived by following tutorials of OpenCV\n",
    "# Load the Data\n",
    "\n",
    "dataset='food_challenge'\n",
    " \n",
    "# Set train and valid directory paths\n",
    "train_directory = 'data/custom_split/train'\n",
    "valid_directory = 'data/custom_split/validation'\n",
    " \n",
    "# Batch size\n",
    "bs = 32\n",
    " \n",
    "# Number of classes\n",
    "num_classes = 80\n",
    " \n",
    "# Load Data from folders\n",
    "data = {\n",
    "    'train': datasets.ImageFolder(root=train_directory, transform=image_transforms['train']),\n",
    "    'valid': datasets.ImageFolder(root=valid_directory, transform=image_transforms['valid']),\n",
    "}\n",
    " \n",
    "# Batch size\n",
    "bs = 32\n",
    "\n",
    "# Number of classes\n",
    "num_classes = len(os.listdir(valid_directory))-1  \n",
    "print(num_classes)\n",
    "\n",
    "# Get a mapping of the indices to the class names, in order to see the output classes of the test images.\n",
    "idx_to_class = {v: k for k, v in data['train'].class_to_idx.items()}\n",
    "# print(idx_to_class)\n",
    "\n",
    "# Size of Data, to be used for calculating Average Loss and Accuracy\n",
    "train_data_size = len(data['train'])\n",
    "valid_data_size = len(data['valid'])\n",
    "\n",
    "# Create iterators for the Data loaded using DataLoader module\n",
    "train_data_loader = DataLoader(data['train'], batch_size=bs, shuffle=True)\n",
    "valid_data_loader = DataLoader(data['valid'], batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate(model, loss_criterion, optimizer, curIteration, scheduler, epochs=25, train_fc=True, save_at_epoch=4):\n",
    "    '''\n",
    "    Function to train and validate\n",
    "    Parameters\n",
    "        :param model: Model to train and validate\n",
    "        :param loss_criterion: Loss Criterion to minimize\n",
    "        :param optimizer: Optimizer for computing gradients\n",
    "        :param epochs: Number of epochs (default=25)\n",
    "  \n",
    "    Returns\n",
    "        model: Last trained model\n",
    "        history: (dict object): Having training loss, accuracy and validation loss, accuracy\n",
    "    '''\n",
    "    \n",
    "    start = time.time()\n",
    "    history = []\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start = time.time()\n",
    "        print(\"Epoch: {}/{}\".format(epoch+1, epochs))\n",
    "        \n",
    "        # Set to training mode\n",
    "        model.train()\n",
    "        \n",
    "        # Loss and Accuracy within the epoch\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "        \n",
    "        valid_loss = 0.0\n",
    "        valid_acc = 0.0\n",
    "        \n",
    "        for i, (inputs, labels) in enumerate(train_data_loader):\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Clean existing gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass - compute outputs on input data using the model\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = loss_criterion(outputs, labels)\n",
    "            \n",
    "            # Backpropagate the gradients\n",
    "            loss.backward()\n",
    "            \n",
    "            # Update the parameters\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Compute the total loss for the batch and add it to train_loss\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            # Compute the accuracy\n",
    "            ret, predictions = torch.max(outputs.data, 1)\n",
    "            correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "            \n",
    "            # Convert correct_counts to float and then compute the mean\n",
    "            acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "            \n",
    "            # Compute total accuracy in the whole batch and add to train_acc\n",
    "            train_acc += acc.item() * inputs.size(0)\n",
    "                    \n",
    "        # Validation - No gradient tracking needed\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # Set to evaluation mode\n",
    "            model.eval()\n",
    "\n",
    "            # Validation loop\n",
    "            for j, (inputs, labels) in enumerate(valid_data_loader):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Forward pass - compute outputs on input data using the model\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                # Compute loss\n",
    "                loss = loss_criterion(outputs, labels)\n",
    "\n",
    "                # Compute the total loss for the batch and add it to valid_loss\n",
    "                valid_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                # Calculate validation accuracy\n",
    "                ret, predictions = torch.max(outputs.data, 1)\n",
    "                correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "\n",
    "                # Convert correct_counts to float and then compute the mean\n",
    "                acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "\n",
    "                # Compute total accuracy in the whole batch and add to valid_acc\n",
    "                valid_acc += acc.item() * inputs.size(0)\n",
    "            \n",
    "        # Find average training loss and training accuracy\n",
    "        avg_train_loss = train_loss/train_data_size \n",
    "        avg_train_acc = train_acc/train_data_size\n",
    "\n",
    "        # Find average validation loss and validation accuracy\n",
    "        avg_valid_loss = valid_loss/valid_data_size \n",
    "        avg_valid_acc = valid_acc/valid_data_size\n",
    "\n",
    "        history.append([avg_train_loss, avg_valid_loss, avg_train_acc, avg_valid_acc])\n",
    "                \n",
    "        epoch_end = time.time()\n",
    "        \n",
    "        # Update scheduler step for epoch\n",
    "        if(scheduler != None):\n",
    "            print(\"Scheduler step\")\n",
    "            scheduler.step()\n",
    "        \n",
    "        print(\"Epoch : {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}%, \\n\\t\\tValidation : Loss : {:.4f}, Accuracy: {:.4f}%, Time: {:.4f}s\".format(epoch, avg_train_loss, avg_train_acc*100, avg_valid_loss, avg_valid_acc*100, epoch_end-epoch_start))\n",
    "        \n",
    "        # Save the model\n",
    "        if train_fc:\n",
    "            torch.save(model, groot+\"/hrvoje/pt/\"+dataset+'_model_'+str(curIteration)+'.pt')\n",
    "        else:\n",
    "            if(epoch == save_at_epoch):\n",
    "                torch.save(model, groot+\"/hrvoje/pt/\"+dataset+'_model_conv_0_'+str(curIteration)+ '.pt') \n",
    "            \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training & Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training for fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting train validation at:\", str(datetime.datetime.now()))\n",
    "\n",
    "for i in range(10):\n",
    "    resnet50 = models.resnet50(pretrained=True)\n",
    "    resnet50 = resnet50.to('cuda:0')\n",
    "    for param in resnet50.parameters(): \n",
    "        param.requires_grad = False\n",
    "\n",
    "    fc_inputs = resnet50.fc.in_features\n",
    " \n",
    "    resnet50.fc = nn.Sequential(\n",
    "        nn.Linear(fc_inputs, 256),  \n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.4),\n",
    "        nn.Linear(256, 80), \n",
    "        nn.LogSoftmax(dim=1) # For using NLLLoss()\n",
    "    )\n",
    "\n",
    "    resnet50 = resnet50.to('cuda:0')\n",
    "\n",
    "    loss_func = nn.NLLLoss()\n",
    "    optimizer = optim.Adam(resnet50.parameters(), lr=0.0001, weight_decay=0.0001)\n",
    "\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    num_epochs = 1\n",
    "    trained_model, history = train_and_validate(resnet50, loss_func, optimizer, i, scheduler, num_epochs)  \n",
    "\n",
    "torch.save(history, groot+\"/hrvoje/\"+dataset+'_history.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training for convolutional layers based on the stored weighted FC layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting train validation at:\", str(datetime.datetime.now()))\n",
    "\n",
    "for i in range(3,10):\n",
    "    fc_trained_model = torch.load(groot+\"/hrvoje/pt/food_challenge_model_\" + str(i) + \".pt\")\n",
    "    for name, child in fc_trained_model.named_children():\n",
    "        if name == 'layer4': #or name == 'layer3' #possibility to unfreeze layer 3\n",
    "            for name2, params in child.named_parameters():\n",
    "                params.requires_grad = True  \n",
    "    \n",
    "    loss_func = nn.NLLLoss()\n",
    "    optimizer = optim.Adam(fc_trained_model.parameters(), lr=0.0001, weight_decay=0.0005)\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.05) \n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    num_epochs = 5\n",
    "    trained_model, history = train_and_validate(fc_trained_model, loss_func, optimizer, i, scheduler, num_epochs, train_fc=False)\n",
    "\n",
    "torch.save(history, groot+\"/hrvoje/\"+dataset+'_history.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
